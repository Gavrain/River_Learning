# 机器学习——logistic回归

## Sigmod函数

![mark](http://ozxf77u6w.bkt.clouddn.com/blog/180315/12LG1eDlm7.png?imageslim)

x的取值范围是负无穷到正无穷的，y的取值是0-1上的值，可以做分类使用，其实是分类的算法

## Grid Descend(梯度下降)

![mark](http://ozxf77u6w.bkt.clouddn.com/blog/180315/kgeChidhKc.png?imageslim)

$\theta_1$是权值参数，$\theta_0$是偏置参数，算计所有的样本的损失函数，样本的多少和损失值没有关系，所以需要除以m

$J(\theta_1,\theta_2)$是损失函数值

$\alpha$是学习率，也可以叫坡度（这个值不能太大，也不能太小的）















