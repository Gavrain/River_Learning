

# 机器学习——线性回归

## 步骤

1）训练样本

2）提取特征

3）学习函数

4）预测

| 工资    | 年龄   | 额度    |
| ----- | ---- | ----- |
| 4000  | 25   | 20000 |
| 8000  | 30   | 70000 |
| 5000  | 28   | 35000 |
| 7500  | 33   | 50000 |
| 12000 | 40   | 85000 |
|       |      |       |

$$
h_\theta(x^{})=\theta_0+\theta_1 X_1+\theta_2 X_2
$$

$$
h_\theta(x^{})=\sum_{i=0}^n \theta_i X_i=\theta^TX
$$

公式（2）：权值和特征的组合


$$
y^{(i)}=\theta^TX^{(i)}+\varepsilon^{(i)}
$$
误差$y^{(i)}=\theta^TX^{(i)}+\varepsilon^{(i)}$中的$\varepsilon^{(i)}$是独立并且具有相同的分布通常认为是服从均值为0方差为$\theta^2$的高斯分

布（正态*分布*（Normal distribution），也称“常态*分布*”，又名*高斯分布*）
$$
f(\varepsilon^{(i)})=\frac{1}{\sqrt{2π}\sigma}*e^{\frac{-(\varepsilon^{(i)}-u)^2}{2\sigma^2}}
$$
其中由于均值u=0,把公式（3）中的数值$\varepsilon^{(i)}=y^{(i)}-\theta^TX^{(i)}$带入到公式（4）中就可以得到(5)


$$
P(y^{(i)}|x^{(i)};\theta)=\frac{1}{\sqrt{2π}\sigma}*e^{\frac{-(y^{(i)}-\theta^TX^{(i)})^2}{2\sigma^2}}
$$
公式（5）的左边表示的是什么样的$\theta​$参数和$X^{(i)}$组合后越接近于$y^{(i)}$的概率值越大的
$$
L(\theta)=\prod_{i=1}^m P(y^{(i)}|x^{(i)};\theta)
$$
$L(\theta)$表示的最大似然函数，对于所有的样本来说，$\theta$参数和$X^{(i)}$组合后概率值是最大的


$$
L(\theta)=\prod_{i=1}^m \frac{1}{\sqrt{2π}\sigma}*e^{\frac{-(y^{(i)}-\theta^TX^{(i)})^2}{2\sigma^2}}
$$
求取$\theta$使得$L(\theta)$的值最大
$$
\varphi(\theta)=logL(\theta)
		       =log\prod_{i=1}^m \frac{1}{\sqrt{2π}\sigma}*e^{\frac{-(y^{(i)}-\theta^TX^{(i)})^2}{2\sigma^2}}
		       =\sum_{i=0}^m log \frac{1}{\sqrt{2π}\sigma}*e^{\frac{-(y^{(i)}-\theta^TX^{(i)})^2}{2\sigma^2}}
		       =mlog\frac{1}{\sqrt{2π}\sigma}-\frac{1}{2\sigma^2}\sum_{i=1}^m (y{(i)-\theta^Tx^{(i)}})^2
$$

$$
J(\theta) = \frac 1 2 \sum_{i=1}^m (h_\theta(x^{(i)})-y^{(i)})^2
$$

最后就是求解使得$J(\theta)$的值越小越好,把式（9）转化为矩阵的形式
$$
J(\theta)=\frac 1 2 (X\theta-y)^T(X\theta-y)
$$
对$\theta$求解偏导数：
$$
\bigtriangledown_\theta J(\theta)=\bigtriangledown_\theta \frac 1 2 (X\theta-y)^T(X\theta-y)   \\ =\bigtriangledown_\theta \frac 1 2 (X^T\theta^T-y^T)(X\theta-y) \\=\bigtriangledown_\theta \frac 1 2(\theta^TX^TX\theta-\theta^TX^Ty-y^TX\theta+y^Ty ) \\=X^TX\theta-X^Ty
$$
因为最后求解的是极值点也就是倒数为0的地方，令（11）=0，得到
$$
\theta=(X^TX)^{(-1)}X^Ty
$$


