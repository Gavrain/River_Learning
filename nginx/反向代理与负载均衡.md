#反向代理和负载均衡

[TOC]

## 介绍Nginx

1、http服务器。Nginx是一个http服务可以独立提供http服务。可以做网页静态服务器。

2、虚拟主机。可以实现在一台服务器虚拟出多个网站。例如个人网站使用的虚拟主机。

3、反向代理，负载均衡。当网站的访问量达到一定程度后，单台服务器不能满足用户的请求时，需要用多台服务器集群可以使用nginx做反向代理。并且多台服务器可以平均分担负载，不会因为某台服务器负载高宕机而某台服务器闲置的情况。

## Nginx实现虚拟机

可以实现在同一台服务器上运行多个网站，而且网站之间是不相互干扰的

桶一个服务器只能有一个ip,网站需要使用的是80端口。网站的域名不同。

区分不同的网站有三种方式：

1、IP区分

2、端口区分

3、域名区分

**通过IP区分虚拟主机**

Linux操作系统允许添加IP别名，IP别名就是在一块物理网卡上绑定多个lP地址。这样就能够在使用单一网卡的同一个服务器上运行多个基于IP的虚拟主机。

1、将/etc/sysconfig/network-scripts/ifcfg-eth0文件复制一份，命名为ifcfg-eth0:1

修改其中内容：

DEVICE=eth0:1

IPADDR=192.168.25.103

其他项不用修改

2、重启系统

 **配置nginx基于ip地址的虚拟主机**

```shel
server {
        listen       80;
        server_name  192.168.25.141;

        #charset koi8-r;

        #access_log  logs/host.access.log  main;

        location / {
            root   html-141;
            index  index.html index.htm;
        }

        
    }

    server {
        listen       80;
        server_name  192.168.25.100;

        #charset koi8-r;

        #access_log  logs/host.access.log  main;

        location / {
            root   html-100;
            index  index.html index.htm;
        }      
    }
```

**基于端口的虚拟主机**

 ```xml
server {
        listen       81;
        server_name  192.168.25.141;

        #charset koi8-r;

        #access_log  logs/host.access.log  main;

        location / {
            root   html-81;
            index  index.html index.htm;
        }
        
    }
    server {
        listen       82;
        server_name  192.168.25.141;

        #charset koi8-r;

        #access_log  logs/host.access.log  main;

        location / {
            root   html-82;
            index  index.html index.htm;
        }        
    }
 ```

**基于域名的虚拟主机**

最有用的虚拟主机配置方式。

一个域名只能绑定一个ip地址，一个ip地址可以被多个域名绑定

  ```xml
server {
        listen       80;
        server_name  www.itheima.com;

        #charset koi8-r;

        #access_log  logs/host.access.log  main;

        location / {
            root   html-www;
            index  index.html index.htm;
        }

        
    }

    server {
        listen       80;
        server_name  hehe.itheima.com;

        #charset koi8-r;

        #access_log  logs/host.access.log  main;

        location / {
            root   html-hehe;
            index  index.html index.htm;
        }     
    }
  ```

## **反向代理**

在计算机世界里，由于单个服务器的处理客户端（用户）请求能力有一个极限，当用户的接入请求蜂拥而入时，会造成服务器忙不过来的局面，可以使用多个服务器来共同分担成千上万的用户请求，这些服务器提供相同的服务，对于用户来说，根本感觉不到任何差别。



<img src="https://pic3.zhimg.com/v2-3b4274d49d3babd1cc2ba521b72892aa_b.jpg" data-rawwidth="400" data-rawheight="199" data-size="normal" class="content_image" width="400">



**反向代理的实现**
1）需要有一个负载均衡设备来分发用户请求，将用户请求分发到空闲的服务器上

2）服务器返回自己的服务到负载均衡设备

3）负载均衡将服务器的服务返回用户

以上的潜台词是：用户和负载均衡设备直接通信，**也意味着用户做服务器域名解析时，解析得到的IP其实是负载均衡的IP，而不是服务器的IP**，这样有一个好处是，当新加入/移走服务器时，仅仅需要修改负载均衡的服务器列表，而不会影响现有的服务。

**实战演示**

在一个虚拟机上创建两个tomcat实例，模拟多个服务器。



通过访问不同的域名访问运行在不同端口的tomcat

8080.itheima.com   访问运行8080端口的tomcat

8081.itheima.com   访问运行8081端口的tomcat

```xml
#配置一个代理即tomcat1服务器    
upstream tomcatserver1 {
	   server 192.168.25.141:8080;
    }
#配置一个代理即tomcat2服务器
    upstream tomcatserver2 {
	   server 192.168.25.141:8081;
    }
#配置一个虚拟主机
   server {
        listen       80;
        server_name  8080.itheima.com;

        #charset koi8-r;

        #access_log  logs/host.access.log  main;
        #域名8080.itheima.com的请求全部转发到tomcat_server1即tomcat1服务上
        location / {
            proxy_pass   http://tomcatserver1;
        #欢迎页面，按照从左到右的顺序查找页面
            index  index.html index.htm;
        }

        
    }
    server {
        listen       80;
        server_name  8081.itheima.com;

        #charset koi8-r;

        #access_log  logs/host.access.log  main;

        location / {
            proxy_pass   http://tomcatserver2;
            index  index.html index.htm;
        }

        
    }

```

## Nginx的负载均衡的实现

使用nginx服务实现负载均衡的时候，用户的访问首先会访问到Nginx服务器，然后Nginx服务器再从服务器集群中选择压力较小的服务器，然后将该访问请求引向该服务器。若服务器集群中的某个某个服务器崩溃了，那么就会从待选的服务器列表中，把该服务器删除；

nginx作为负载均衡服务器，用户请求先到达nginx，再由nginx根据负载配置将请求转发至 tomcat服务器。

       nginx负载均衡服务器：192.168.25.141
    
       tomcat1服务器：192.168.25.141:8080
    
       tomcat2服务器：192.168.25.141:8081

![mark](http://ozxf77u6w.bkt.clouddn.com/blog/180905/LFgiGhHge4.png?imageslim)

**配置负载均衡的权重**

![mark](http://ozxf77u6w.bkt.clouddn.com/blog/180905/b79HFid915.png?imageslim)

```
节点说明：
在http节点里添加:

#定义负载均衡设备的 Ip及设备状态 
upstream myServer {   

    server 127.0.0.1:9090 down; 
    server 127.0.0.1:8080 weight=2; 
    server 127.0.0.1:6060; 
    server 127.0.0.1:7070 backup; 
}

在需要使用负载的Server节点下添加

proxy_pass http://myServer;

upstream 每个设备的状态:

down 表示单前的server暂时不参与负载 
weight  默认为1.weight越大，负载的权重就越大。 
max_fails ：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream 模块定义的错误 
fail_timeout:max_fails 次失败后，暂停的时间。 
backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。

```

## Nginx的负载均衡策略

**1、轮询（默认）**

**2、指定权重**

3、 **ip_hash**
每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。  	

## Nginx高可用（keepalived）

解决高可用的方案就是添加冗余。添加备份机

keepalived是集群中保证高可用的一个服务软件，用单点故障；

keepalived是用来检测web服务器的状态，如果一台web服务器宕机，或工作出现故障，keepalived将检测到，并且将故障的web服务器从系统中移除，当web服务器工作正常后keepalived自动将web服务器加到服务器集群中。这些工作全部是自动的完成时，不需要手动的进行干预，人只需要做的就是修复web服务器，让web服务器恢复的到正常的状态。

## Keepalived工作原理

keepalived是以VRRP协议为实现基础的，VRRP全称为Virtual Router Redundancy Protocol即虚拟路由冗余协议，虚拟路由冗余协议，可以认为是实现路由器高可用的协议，即将N台提供相同功能路由器组成一个路由组，这个组里面有一个master 和多个backup,master上面有一个对外提供服务的VIP(Virtual IP Address,虚拟IP地址)，master会发送组播，当backup收不到VRRP包时，就 认为master宕机，这个时候就需要根据VRRP的优先级来选举一个backup当master。这样就可以保证路由的高可用了

keepalived主要有三个模块，分别是core，check，和VRRP,core模块为keepalived的核心，负责的是主进程的启动，维护，以及全局配置文件的加载和解析。check负责的是健康的检查，使用的是VRRP









