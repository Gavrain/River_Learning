# 相似度之间的计算

计算用户或者是商品的相似度

![1542254052934](../../../../../AppData/Local/Temp/1542254052934.png)

在数据分析和数据挖掘以及搜索引擎中，我们经常需要知道个体间差异的大小，进而评价个体的相似性和类别。常见的比如数据分析中比如相关分析，数据挖掘中的分类聚类（K-Means等）算法，搜索引擎进行物品推荐时。

相似度就是比较两个事物的相似性。一般通过计算事物的特征之间的距离，如果距离小，那么相似度大；如果距离大，那么相似度小。比如两种水果，将从颜色，大小，维生素含量等特征进行比较相似性。

问题定义：有两个对象X,Y,都包含N维特征，X=(x1,x2,x3,……..,xn),Y=(y1,y2,y3,……..,yn),计算X和Y的相似性。常用的有五种方法，如下。

## 1、欧几里得距离（Eucledian Distance）

欧氏距离是最常用的距离计算公式，衡量的是多维空间中各个点之间的绝对距离，当数据很稠密并且连续时，这是一种很好的计算方式。

因为计算是基于各维度特征的绝对数值，所以欧氏度量需要保证各维度指标在相同的刻度级别，比如对身高（cm）和体重（kg）两个单位不同的指标使用欧式距离可能使结果失效。 





所以$sim(x,y)=\frac{1}{1+d(x,y)}$

## 2、皮尔森相关系数(Pearson Correlation Coefficient)

又称相关相似性，通过Peason相关系数来度量两个用户的相似性。计算时，首先找到两个用户共同评分过的项目集，然后计算这两个向量的相关系数。

 公式：  

![1542338948235](../../../../../AppData/Local/Temp/1542338948235.png)

协方差 $cov(X,Y)=\frac{\sum_n^{i=1}(x_i-\overline{x})(y_i-\overline{y})}{n-1}$协方差是用来衡量X和Y的变化的趋势是不是一致的，取值的范围是[-1,1]上的，越是趋近于1说明的就是X和Y是完全的正相关的

皮尔逊相关系数 ：${}\rho_{x,y}=corr(x,y)=\frac{cov(x,y)}{\sigma{x}\sigma{y}}=\frac{E[(x-\mu(x))(y-\mu_y]}{\sigma{x}\sigma{y}} $

Pearson相关系数是用协方差除以两个变量的标准差得到的

## 3、（余弦相似度）Cosine Similarity

余弦相似度用向量空间中两个向量夹角的余弦值作为衡量两个个体间差异的大小。相比距离度量，余弦相似度更加注重两个向量在方向上的差异，而非距离或长度上。  

![1542362960004](../../../../../AppData/Local/Temp/1542362960004.png)

![1542362998068](../../../../../AppData/Local/Temp/1542362998068.png)

![1542363135644](../../../../../AppData/Local/Temp/1542363135644.png)

、

