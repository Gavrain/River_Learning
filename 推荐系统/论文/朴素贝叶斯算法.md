#  朴素贝叶斯算法

## 数学公式

[TOC]

**联合概率**：包含多个条件，且所有条件同时成立的概率

记作：P(A,B)

**条件概率**：就是事件A在另外一个事件B已经发生条件下的发生概率

记作：P(A|B)

特性：P(A1,A2|B) = P(A1|B)P(A2|B)

注意：此条件概率的成立，是由于A1,A2相互独立的结果

**全概率公式**

1. 如果事件组B1，B2，.... 满足

​               1.B1，B2....两两互斥，即 Bi ∩ Bj = ∅ ，i≠j ， i,j=1，2，....，且P(Bi)>0,i=1,2,....;

​               2.B1∪B2∪....=Ω ，则称事件组 B1,B2,...是样本空间Ω的一个划分

​          设 B1,B2,...是样本空间Ω的一个划分，A为任一事件，则：

![mark](http://www.hhaxmm.cn/blog/20181216/bE6p6uQpvViX.png)

上式即为全概率公式（formula of total probability)

2. 全概率公式的意义在于，当直接计算P(A)较为困难,而P(Bi),P(A|Bi)  (i=1,2,...)的计算较为简单时，可以利用全概率公式计算P(A)。思想就是，将事件A分解成几个小事件，通过求小事件的概率，然后相加从而求得事件A的概率，而将事件A进行分割的时候，不是直接对A进行分割，而是先找到样本空间Ω的一个个划分B1,B2,...Bn,这样事件A就被事件AB1,AB2,...ABn分解成了n部分，即A=AB1+AB2+...+ABn, 每一Bi发生都可能导致A发生相应的概率是P(A|Bi)，由加法公式得

​         P(A)=P(AB1)+P(AB2)+....+P(ABn)

​               =P(A|B1)P(B1)+P(A|B2)P(B2)+...+P(A|Bn)P(PBn)

**贝叶斯公式**

​      1.与全概率公式解决的问题相反，贝叶斯公式是建立在条件概率的基础上寻找事件发生的原因（即大事件A已经发生的条件下，分割中的小事件Bi的概率），设B1,B2,...是样本空间Ω的一个划分，则对任一事件A（P(A)>0),有

​               ![mark](http://www.hhaxmm.cn/blog/20181216/5dnyDaUeA6Vk.png)

​         上式即为贝叶斯公式（Bayes formula)，Bi 常被视为导致试验结果A发生的”原因“，P(Bi)(i=1,2,...)表示各种原因发生的可能性大小，故称先验概率；P(Bi|A)(i=1,2...)则反映当试验产生了结果A之后，再对各种原因概率的新认识，故称后验概率。

![mark](http://www.hhaxmm.cn/blog/20181216/enMmE2PR9D0O.png)

## 朴素贝叶斯Naive Bayes

朴素贝叶斯之所以成为朴素就是特征独立

P(科技 | 文档) ：现在是给了某一个文档求出它所属于哪一个类别(科技)的概率

P(娱乐 | 文档)：给定了一个文档求出他是娱乐的概率

给文档就是意味着给了一个个的词，文档：词1，词2，词3，词4

![mark](http://www.hhaxmm.cn/blog/20181216/NKT3BKH5qFSM.png)

注：w为给定文档的特征值(频数统计,预测文档提供)，c为文档类别

公式可以理解为：

P(C│F1,F2,…)=(P(F1,F2,… │C)P(C)) /  (P(F1,F2,…))

其中c可以是不同类别

公式分为三个部分：

- P(C)：每个文档类别的概率(某文档类别词数／总文档词数)

- P(W│C)：给定类别下特征（被预测文档中出现的词）的概率

  - 计算方法：P(F1│C)=Ni/N  （训练文档中去计算）

    Ni为该F1词在C类别所有文档中出现的次数

    N为所属类别C下的文档所有词出现的次数和

- P(F1,F2,…)     预测文档中每个词的概率 

![mark](http://www.hhaxmm.cn/blog/20181216/RmJTER9wJVh9.png)

> 问题：从上面的例子我们得到娱乐概率为0，这是不合理的，如果词频列表里面有很多出现次数都为0，很可能计算结果都为零

解决方法：拉普拉斯平滑系数  P(F1│C)=(Ni+α)/(N+αm)   α为指定的系数一般为1，m为训练文档中统计出的特征词个数

## 分类模型评估

在分类任务下，预测结果(Predicted Condition)与正确标记(True Condition)之间存在四种不同的组合，构成混淆矩阵(适用于多分类)

![mark](http://www.hhaxmm.cn/blog/20181216/wsIqlNBsy7BV.png)

#### 精确率：预测结果为正例样本中真实为正例的比例（查得准）

![mark](http://www.hhaxmm.cn/blog/20181216/aFl0bLILgyTi.png)





#### 召回率：真实为正例的样本中预测结果为正例的比例（查的全，对正样本的区分能力）

![mark](http://www.hhaxmm.cn/blog/20181216/ngwb78nQjWlz.png)





#### 其他分类标准，F1-score，反映了模型的稳健型

![mark](http://www.hhaxmm.cn/blog/20181216/byyj6XBGRl78.png)

#### 分类模型评估API

sklearn.metrics.classification_report(y_true, y_pred, target_names=None)

y_true：真实目标值

y_pred：估计器预测目标值

target_names：目标类别名称

return：每个类别精确率与召回率









