## 1、支付问题

## 如何避免重复的下单

可能会出现订单重复提交的情况如下几种：

>1: 在网络延迟的情况下让用户有时间点击多次submit按钮导致表单重复提交
>
>2:  表单提交后用户点击【刷新】按钮导致表单重复提交
>
>3: 用户提交表单后，点击浏览器的【后退】按钮回退到表单页面后进行再次提交

**解决的方式：**

1：ajax的分段提交

第一段：保存订单，这个时候会创建订单，并且有个返回一个JSON，里面有状态值

第二段：根据成功的状态，把当前的URL做一个跳转。跳转到支付的页面中去

2：form的token来做

Java 使用Token令牌防止表单重复提交的步骤：

- 在服务器端生成一个唯一的随机标识号，专业术语称为Token(令牌)，同时在当前用户的Session域中保存这个Token。 
- 将Token发送到客户端的Form表单中，在Form表单中使用隐藏域来存储这个Token，表单提交的时候连同这个Token一起提交到服务器端。
- 在服务器端判断客户端提交上来的Token与服务器端生成的Token是否一致，
- 如果不一致，那就是重复提交了，此时服务器端就可以不处理重复提交的表单。如果相同则处理表单提交，处理完后清除当前用户的Session域中存储的标识号。

**在下列情况下，服务器程序将拒绝处理用户提交的表单请求：**

- 存储Session域中的Token(令牌)与表单提交的Token(令牌)不同。   
- 当前用户的Session中不存在Token(令牌)。



### 如何避免对同一个订单进行多次的付款

可能会出现这么的一种情况：

> 订单已下单成功并且正处于支付页面，用户调起支付网关进行支付。支付扣款成功，但是返回结果的时候网络异常，此时钱已经扣了 ，用户再次点击按钮 ，此时会进行第二次扣款，返回结果成功，用户查询余额返发现多扣钱了 

简单的方式：

**1：查询订单的支付状态**

用户调用支付，扣款成功后，更新对应订单状态，然后再保存流水 

步骤：

1、查询订单支付状态

2、如果已经支付，直接返回结果

3、如果未支付，则支付扣款并且保存流水

4、返回支付结果

如果步骤4通信失败，用户再次发起请求，那么最终结果还是一样的

**2：使用tickId的方式**

1. 异步请求获取门票
2. 调用支付，传入门票
3. 根据门票ID查询此次操作是否存在，如果存在则表示该操作已经执行过，直接返回结果；如果不存在，支付扣款，保存结果,删除token
4. 返回结果到客户端



## 2:超时取消订单

Quartz（扩子）的核心接口：

- Schedule -核心调度器：是最核心的概念，需要把JobDetail和Trigger注册到scheduler中，才可以执行 
- Job-任务：执行任务的规则；比如每天，每小时等  
- JobDetail-任务细节：Quartz执行Job时，需要新建个Job实例，但是不能直接操作Job类，所以通过JobDetail来获取Job的名称、描述信息。 
- Trigger-触发器 ：表示一个调度参数的配置，通过配置它，来告诉调度器什么时候去调用JobDetail

![mark](http://ozxf77u6w.bkt.clouddn.com/blog/180816/KD69EId6bj.png?imageslim)

Job、JobDetail和Trigger一起注册到Scheduler调度器，

调度器按照时间的推移去执行触发器，最后就执行到任务job

**重点就是写触发器**

Trigger:

- **SimpleTrigger**:简单触发
- **cronTrigger**：表达式触发

Quartz与Spring进行整合：

配置文件.xml

```
1: 定义任务
2：触发器
3：调度器
```

一个触发能都多个job吗？ 不能！

一个job能有多个触发吗？ 是的！

### 超时的订单关闭

1：定义job

- 扫描订单表，修改订单的状态为关闭状态
- 扫描条件：创建时间 <= 当前的时间-24小时  ，

2：定义触发

- 理论上需要的是实时触发，但是这样会存在性能问题
- 1分钟触发一次

实现的具体细节：

job的实现的细节

```
1：获取到spring的容器
2：在dao层创建一个mapper扫描订单表，mapper的配置文件的Sql是
3：传入的时间`new DateTime().minusHours(24).toDate()`
```

##3、价格规则业务

数据库表的字段 : 规则ID  校区的名称    开始的时间   结束的时间   课程的数量    价格

现在需要向数据库中插入一条规则，

> 这个时候的插入的数据就需要考虑到时间是否有交叉的，假如说我们插入到某一个校区的价格规格在时间上与数据库中已经存在的时间有交叉行为，并且价格还不一样，这样是不可行的

我使用的是mybatis - generator -plugin自动生成的mapper进行做的，

1：在数据库中查询是否有开始时间在我需要插入的时间之间的数据，如果有说明是有交叉的

2：在数据库中查询是否有结束时间在我需要插入的时间之间的数据，如果有说明是有交叉的

3：在数据库中查询是否有开始时间比我插入的开始时间还小，结束时间比我插入的结束时间还大的数据，如果存在的话，说明有包含的关系



##  **4：登录的时候注意的问题点**

其基本想法是这样的：当用户首次提供密码时（通常是注册时），由系统自动往这个密码里撒一些“佐料”，然后再散列。而当用户登录时，系统为用户提供的代码撒上同样的“佐料”，然后散列，再比较散列值，已确定密码是否正确。 

这里的“佐料”被称作“Salt值”，这个值是由系统随机生成的，并且只有系统知道。这样，即便两个用户使用了同一个密码，由于系统为它们生成的salt值不同，他们的散列值也是不同的。即便黑客可以通过自己的密码和自己生成的散列值来找具有特定密码的用户，但这个几率太小了（密码和salt值都得和黑客使用的一样才行）。 

用户注册时，

1. 用户输入【账号】和【密码】（以及其他用户信息）；
2. 系统为用户生成【Salt值】；
3. 系统将【Salt值】和【用户密码】连接到一起；
4. 对连接后的值进行散列，得到【Hash值】；
5. 将【Hash值1】和【Salt值】分别放到数据库中。

用户登录时，

1. 用户输入【账号】和【密码】；
2. 系统通过用户名找到与之对应的【Hash值】和【Salt值】；
3. 系统将【Salt值】和【用户输入的密码】连接到一起；
4. 对连接后的值进行散列，得到【Hash值2】（注意是即时运算出来的值）；
5. 比较【Hash值1】和【Hash值2】是否相等，相等则表示密码正确，否则表示密码错误。

有时候，为了减轻开发压力，程序员会统一使用一个salt值（储存在某个地方），而不是每个用户都生成私有的salt值。



## 5：如何处理前端错误的请求

我们返回的数据是以JSON的形式进行返回的，我们自己定义了一个JSON的返回格式，返回的JSON包括三个字段，code状态码（状态码定义了两种状态：SUCCESS ERROR），data返回的数据，msg返回的信息

假如传入了一个不存在的校区ID

> 也是会去数据库中进行查询，如果查询出来的结果为空的情况下，会返回一个JSON，JSON的code状体码为ERROR,data为空，msg为校区不存在；

##6网络请求超时处理



## 7 如果一个节点挂了怎么办

**要搭建一个高可用的 ZooKeeper 集群** 

组成 ZooKeeper 集群的每台机器都会在内存中维护当前的服务器状态，并且每台机器之间都会互相保持通信。

> 重要的一点是，只要集群中存在超过一半的机器能够正常工作，那么整个集群就能够正常对外服务。

ZooKeeper 的客户端程序会选择和集群中的任意一台服务器创建一个 TCP 连接，而且一旦客户端和服务器断开连接，客户端就会自动连接到集群中的其他服务器。

Zookeeper所提供的服务涵盖：主从协调（谁是主服务器，谁是从的服务器）、服务器节点动态上下线（哪个服务器挂掉了）、统一配置管理（配置文件的统一的管理）、分布式共享锁、统一名称服务（服务器注册名称，客户端通过名称就可以找到ip）……

虽然说可以提供各种服务，但是zookeeper在底层其实只提供了两个功能：

1：管理(存储，读取)用户程序提交的数据(状态数据，描述信息 )；

2：并为用户程序提供数据节点监听服务；

 Zookeeper集群的角色：  Leader 和  follower  （Observer）

**还有一种是NGINX + keepalived的方式实现高可用**

keepalived是集群管理中保证集群高可用的一个服务软件，用来防止单点故障。

Keepalived的作用是检测web服务器的状态，如果有一台web服务器死机，或工作出现故障，Keepalived将检测到，并将有故障的web服务器从系统中剔除，当web服务器工作正常后Keepalived自动将web服务器加入到服务器群中，这些工作全部自动完成，不需要人工干涉，需要人工做的只是修复故障的web服务器。

>keepalived是以VRRP协议为实现基础的，即[虚拟路由冗余协议](http://en.wikipedia.org/wiki/VRRP)。
>
>虚拟路由冗余协议，可以认为是实现路由器高可用的协议，即将N台提供相同功能的路由器组成一个路由器组，这个组里面有一个master和多个backup，master上面有一个对外提供服务的vip（该路由器所在局域网内其他机器的默认路由为该vip），master会发组播，当backup收不到vrrp包时就认为master宕掉了，这时就需要根据[VRRP的优先级](http://tools.ietf.org/html/rfc5798#section-5.1)来[选举一个backup当master](http://en.wikipedia.org/wiki/Virtual_Router_Redundancy_Protocol#Elections_of_master_routers)。这样的话就可以保证路由器的高可用了。

 

## 8:如果客户端请求过大怎么办

1.硬件升级

配置更好的服务器

2：负载均衡 

它是根据某种负载策略把请求分发到集群中的每一台服务器上，让整个服务器群来处理网站的请求 

3：服务器集群 

 服务器集群就是指将N台服务器集中起来一起进行同一种服务，它们之间通过网络实现通信。让N台服务器之间相互协作，共同承载一个网站的请求压力。

在客户端看来就像是只有一个服务器。集群可以利用多个计算机进行并行计算从而获得很高的计算速度，也可以用多个计算机做备份，从而使得任何一个机器坏了整个系统还是能正常运行



## 9：数据库上可以做的优化

**1.数据库读写分离**

基本的原理是让主数据库处理事务性增、改、删操作（INSERT、UPDATE、DELETE），而从数据库处理SELECT查询操作。

**2.数据库分表技术（水平分割）**

**水平分割根据某些条件将数据放到两个或多个独立的表中**。即按记录进分分割，不同的记录可以分开保存，每个子表的列数相同。水平切割将表分为多个表。每个表包含的列数相同，但是数据行更少。 （例如，可以将一个包含十亿行的表水平分区成 12 个表，每个小表表示特定年份内一个月的数据。任何需要特定月份数据的查询只需引用相应月份的表。 ）

**假如每个地区的学生数量特别的的时候可以根据校区的维度进行分平分割**

**水平分割优点：** 
1：降低在查询时需要读的数据和索引的页数，同时也降低了索引的层数，加快了查询速度。

**水平分割缺点：** 

2：水平分割会给应用增加复杂度，它通常在查询时需要多个表名，查询所有数据需要union操作。在许多数据库应用中，这种复杂性会超过它带来的优点，因为只要索引关键字不大，则在索引用于查询时，表中增加两到三倍数据量，查询时也就增加读一个索引层的磁盘次数。 

**3.表建立相应的索引**

使用索引可快速访问数据库表中的特定信息。

经常与其他表进行连接的表，在连接字段上应该建立索引； 

KEY `idx` (`arrange_id`,`work_status`)

给作业的状态建立索引，学生可能会经常查询他的那些作业是有效的，还是作废的，这个时候就需要去根据作业的状态进行查询，这个时候在作业状态上设置索引

在后台需要根据教授的名称查询教授的信息的时候可以给教授建立索引



## 10:使用redis做缓存

拿大型网站来举个例子，比如a网站首页一天有100万人访问，其中有一个板块为推荐新闻。要是直接从数据库查询，那么一天就要多消耗100万次数据库请求。上面已经说过，Redis支持丰富的数据类型，所以这完全可以用Redis来完成，将这种热点数据存到Redis（内存）中，要用的时候，直接从内存取，极大的提高了速度和节约了服务器的开销。 

**1．在主页中显示最新的项目列表。**

Redis使用的是常驻内存的缓存，速度非常快。LPUSH用来插入一个内容ID，作为关键字存储在列表头部。LTRIM用来限制列表中的项目数最多为5000。如果用户需要的检索的数据量超越这个缓存容量，这时才需要把请求发送到数据库。

**2．删除和过滤。**

如果一篇文章被删除，可以使用LREM从缓存中彻底清除掉。 

**3．排行榜及相关问题。**

排行榜（leader board）按照得分进行排序。ZADD命令可以直接实现这个功能，而ZREVRANGE命令可以用来按照得分来获取前100名的用户，ZRANK可以用来获取用户排名，非常直接而且操作容易。

**4．按照用户投票和时间排序。**

这就像Reddit的排行榜，得分会随着时间变化。LPUSH和LTRIM命令结合运用，把文章添加到一个列表中。一项后台任务用来获取列表，并重新计算列表的排序，ZADD命令用来按照新的顺序填充生成列表。列表可以实现非常快速的检索，即使是负载很重的站点。

**5．过期项目处理。**

使用unix时间作为关键字，用来保持列表能够按时间排序。对current_time和time_to_live进行检索，完成查找过期项目的艰巨任务。另一项后台任务使用ZRANGE...WITHSCORES进行查询，删除过期的条目。

**6．计数。**

进行各种数据统计的用途是非常广泛的，比如想知道什么时候封锁一个IP地址。INCRBY命令让这些变得很容易，通过原子递增保持计数；GETSET用来重置计数器；过期属性用来确认一个关键字什么时候应该删除。

**7．特定时间内的特定项目。**

这是特定访问者的问题，可以通过给每次页面浏览使用SADD命令来解决。SADD不会将已经存在的成员添加到一个集合。
 **轮询(Round Robin)**

轮询是一种很简单的实现，依次将请求分配给后端服务器。优点就是实现简单，请求均匀分配。
缺点也恰恰在于请求均匀分配，因为后端服务器通常性能会有差异，所以希望性能好的服务器能够多承担一部分。也不适合对长连接和命中率有要求的场景。

**加权轮询(Weighted Round Robin)**

加权本质是一种带优先级的方式，加权轮询就是一种改进的轮询算法，轮询算法是权值相同的加权轮询。需要给后端每个服务器设置不同的权值，决定分配的请求数比例。这个算法应用就相当广泛了，对于无状态的负载场景，非常适合。
优点解决了服务器性能不一的情况，缺点是权值需要静态配置，无法自动调节。也不适合对长连接和命中率有要求的场景。

 **随机Random**

随机把请求分配给后端服务器。请求分配的均匀程度依赖于随机算法了，因为实现简单，常常用于配合处理一些极端的情况，如出现热点请求，这个时候就可以random到任意一台后端，以分散热点。当然缺点也不言而喻。

**哈希Hash**

哈希算法想必大家并不陌生，应用最为广泛。根据Source IP、 Destination IP、URL、或者其它，算hash值或者md5，再采用取模。比如有N台服务器: S1、S2、S3……Sn

 

 ##单点登录功能(sso)



 用户只需要登录一次就可以访问所有相互信任的应用系统。

它包括可以将这次主要的登录映射到其他应用中用于同一个用户的登录的机制。

在集群环境中**每个工程都有自己的session**，如果把用户信息写入session而不

共享的话，会出现用户反复登录的情况。

方案一：session共享，其他的tomcat做session共享

方案二：把session数据存放在redis。优点：redis存取速度快，不会出现多个节点session复制的问题。效率高

Token:相当于是一个sessionID（当前会话）；把对应的用户信息写到redis里面，key就相当于是token,value就是用户信息。为了保证其他系统在进行访问的时候也知道你是谁，就需要把token写到cookie里 

注册：数据校验，用户注册

登录：接收用户名和密码，到数据库中查询，根据用户名查询用户信息，查到之后进行密码比对，需要对密码进行md5加密后进行比对。比对成功后说明登录成功，需要生成一个token可以使用UUID。需要把用户信息写入redis，key就是token，value就是用户信息。返回token字符串。

通过token查询用户信息：根据token判断用户是否登录或者session是否过期。接收token，根据token到redis中取用户信息。判断token字符串是否对应用户信息，如果不对应说明token非法或者session已过期。取到了说明用户就是正常的登录状态。返 回用户信息，同时重置用户的过期时间

 

